{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6aacca6",
   "metadata": {},
   "source": [
    "# Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ca0dbcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import cv2\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259606f2",
   "metadata": {},
   "source": [
    "# Unzip the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "714675a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the zipfile module \n",
    "from zipfile import ZipFile \n",
    "  \n",
    "# loading the temp.zip and creating a zip object \n",
    "with ZipFile(\"./face-anonymizer-ptyhon-master.zip\", 'r') as zObject: \n",
    "    # Extracting specific file in the zip \n",
    "    # into a specific location. \n",
    "    unzip_dir = './unzip'\n",
    "    if not os.path.exists(unzip_dir):\n",
    "        os.makedirs(unzip_dir)\n",
    "    zObject.extractall(path=\"./output_dir\") \n",
    "zObject.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab56bca",
   "metadata": {},
   "source": [
    "# Face Anonymyzer Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c7683b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_img(img, face_detection):\n",
    "\n",
    "    H, W, _ = img.shape\n",
    "    print(H, W, _)\n",
    "\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    out = face_detection.process(img_rgb)\n",
    "\n",
    "    if out.detections is not None:\n",
    "        for detection in out.detections:\n",
    "            \n",
    "            location_data = detection.location_data\n",
    "            bbox = location_data.relative_bounding_box\n",
    "            print(bbox)\n",
    "\n",
    "            x1, y1, w, h = bbox.xmin, bbox.ymin, bbox.width, bbox.height\n",
    "\n",
    "            x1 = int(x1*W)\n",
    "            y1 = int(y1*H)\n",
    "            w = int(w * W)\n",
    "            h = int(h * H)\n",
    "\n",
    "            print(x1, y1, w, h)\n",
    "\n",
    "            # blur faces\n",
    "            img[y1:y1 + h, x1:x1 + w, :] = cv2.blur(img[y1:y1 + h, x1:x1 + w, :], (30, 30))\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f233bf",
   "metadata": {},
   "source": [
    "# Argument Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5f490d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image\n",
      "./unzip/Danish Ali.jpg\n"
     ]
    }
   ],
   "source": [
    "args = argparse.ArgumentParser()\n",
    "\n",
    "args.add_argument(\"--mode\", default='image')\n",
    "args.add_argument(\"--filePath\", default='./unzip/Danish Ali.jpg')\n",
    "\n",
    "args = args.parse_args(args=[])\n",
    "print(args.mode)\n",
    "print(args.filePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349a010b",
   "metadata": {},
   "source": [
    "# Making Output Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ebe3adb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = './output'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11565456",
   "metadata": {},
   "source": [
    "# Media Pipe ML Face Detection Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "518e5bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "419 317 3\n",
      "xmin: 0.2759319543838501\n",
      "ymin: 0.2773107588291168\n",
      "width: 0.4514608383178711\n",
      "height: 0.3415416181087494\n",
      "\n",
      "87 116 143 143\n"
     ]
    }
   ],
   "source": [
    "mp_face_detection = mp.solutions.face_detection\n",
    "\n",
    "with mp_face_detection.FaceDetection(model_selection=0, min_detection_confidence=0.5) as face_detection:\n",
    "    \n",
    "    if args.mode in [\"image\"]:\n",
    "        # read image\n",
    "        img = cv2.imread(args.filePath)\n",
    "\n",
    "        img = process_img(img, face_detection)\n",
    "\n",
    "        # save image\n",
    "        cv2.imwrite(os.path.join(output_dir, 'output.png'), img)\n",
    "        cv2.imshow('img',img)\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "    elif args.mode in ['video']:\n",
    "\n",
    "        cap = cv2.VideoCapture(args.filePath)\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        output_video = cv2.VideoWriter(os.path.join(output_dir, 'output.mp4'),\n",
    "                                       cv2.VideoWriter_fourcc(*'MP4V'),\n",
    "                                       25,\n",
    "                                       (frame.shape[1], frame.shape[0]))\n",
    "\n",
    "        while ret:\n",
    "\n",
    "            frame = process_img(frame, face_detection)\n",
    "\n",
    "            output_video.write(frame)\n",
    "\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "        cap.release()\n",
    "        output_video.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b3b91d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8368f31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
